{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import requests\n",
    "from pdfminer.high_level import extract_text\n",
    "import openai"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Steps to get benchmark results out of the pdfs\n",
    "1. load the pdfs from the list of urls\n",
    "2. extract the text from the pdfs\n",
    "3. prompt chatgpt with the text from each pdf\n",
    "4. save the results to a csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                              Title  \\\nPublication date                                                      \n2020/06/01        ADAHESSIAN: An Adaptive Second Order Optimizer...   \n2020/05/16                 MicroNet for Efficient Language Modeling   \n2020/05/06        Learning Architectures from an Extended Search...   \n2020/04/30        Segatron: Segment-Aware Transformer for Langua...   \n2020/03/17        PowerNorm: Rethinking Batch Normalization in T...   \n\n                                              Link  \nPublication date                                    \n2020/06/01        https://arxiv.org/pdf/2006.00719  \n2020/05/16        https://arxiv.org/pdf/2005.07877  \n2020/05/06        https://arxiv.org/pdf/2005.02593  \n2020/04/30        https://arxiv.org/pdf/2004.14996  \n2020/03/17        https://arxiv.org/pdf/2003.07845  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Link</th>\n    </tr>\n    <tr>\n      <th>Publication date</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020/06/01</th>\n      <td>ADAHESSIAN: An Adaptive Second Order Optimizer...</td>\n      <td>https://arxiv.org/pdf/2006.00719</td>\n    </tr>\n    <tr>\n      <th>2020/05/16</th>\n      <td>MicroNet for Efficient Language Modeling</td>\n      <td>https://arxiv.org/pdf/2005.07877</td>\n    </tr>\n    <tr>\n      <th>2020/05/06</th>\n      <td>Learning Architectures from an Extended Search...</td>\n      <td>https://arxiv.org/pdf/2005.02593</td>\n    </tr>\n    <tr>\n      <th>2020/04/30</th>\n      <td>Segatron: Segment-Aware Transformer for Langua...</td>\n      <td>https://arxiv.org/pdf/2004.14996</td>\n    </tr>\n    <tr>\n      <th>2020/03/17</th>\n      <td>PowerNorm: Rethinking Batch Normalization in T...</td>\n      <td>https://arxiv.org/pdf/2003.07845</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the list of urls\n",
    "sample_papers = pd.read_csv('language_benchmarks/sample_papers.csv', index_col=0)\n",
    "sample_papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# load the pdfs from the list of urls\n",
    "for paper_url in sample_papers['Link']:\n",
    "    paper_id = paper_url.split('/')[-1]\n",
    "    download = requests.get(paper_url)\n",
    "    # with open(f'papers/{paper_id}.pdf', 'wb') as f:\n",
    "    #     f.write(download.content)\n",
    "    paper_text = extract_text(f'papers/{paper_id}.pdf')\n",
    "    with open(f'papers/{paper_id}.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(paper_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "CHATGPT_PROMPT = \"\"\"\n",
    "Below is an an excerpt from a machine learning research paper about language modeling. Read it and answer the following questions.\n",
    "1. What is the perplexity of the model when evaluated on language benchmarks such as WikiText-103, enwik8, and Penn TreeBank? State the benchmark and the score.\n",
    "2. What is the language pretraining dataset? How many words or tokens was the model trained on?\n",
    "3. What is the size of the machine learning model, in number of parameters?\n",
    "4. What is the publication date of the paper?\n",
    "If the answer is not in the text, answer \"not in text\".\n",
    "\n",
    "Here are some example answers:\n",
    "1. WikiText-103, perplexity 18.3\n",
    "2. BookCorpus, 800 million words\n",
    "3. 1.5 billion parameters\n",
    "4. 2020-05-28\n",
    "\n",
    "The paper is below this line:\n",
    "====\n",
    "{paper_text}\n",
    "====\n",
    "Answer:\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "response = None"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
